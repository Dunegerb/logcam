<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Project Chimera: Cinematic PWA</title>
    
    <style>
        :root {
            --primary-color: #ff4757; /* A vibrant, "recording" red */
            --secondary-color: #2f3640; /* Deep charcoal for the UI */
            --tertiary-color: #718093; /* Muted grey for inactive elements */
            --accent-color: #00a8ff; /* A sharp blue for highlights and LOG mode */
            --text-color: #f5f6fa;
            --font-family: 'SF Pro Display', 'Roboto', 'Helvetica Neue', sans-serif;
            --transition-speed: 0.3s;
        }

        /* Foundational Reset & Body Styling */
        *, *::before, *::after {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
            -webkit-tap-highlight-color: transparent;
        }

        html, body {
            width: 100%;
            height: 100%;
            overflow: hidden;
            background-color: #000;
            color: var(--text-color);
            font-family: var(--font-family);
            font-synthesis: none;
            text-rendering: optimizeLegibility;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        /* App Container: The Main Stage */
        #app-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            justify-content: center;
            align-items: center;
            background: #000;
        }

        #camera-feed {
            display: none; /* The raw, unprocessed feed is never shown to the user. It's merely a data source. */
        }

        #main-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover; /* Ensures the cinematic vision fills the screen */
        }

        /* UI Overlay: The Command Deck */
        #ui-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            pointer-events: none; /* Allow clicks to pass through to canvas if needed, but controls will override */
            z-index: 10;
        }
        
        /* Top & Bottom Bars */
        .ui-bar {
            width: 100%;
            padding: 15px 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: linear-gradient(to bottom, rgba(0,0,0,0.7), rgba(0,0,0,0));
            pointer-events: all;
        }

        .ui-bar.bottom {
            background: linear-gradient(to top, rgba(0,0,0,0.7), rgba(0,0,0,0));
            justify-content: center;
        }

        /* Status Indicators: The Vitals */
        #status-indicators {
            display: flex;
            gap: 20px;
            align-items: center;
        }

        .status-item {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
            font-weight: 600;
            letter-spacing: 0.5px;
            text-shadow: 0 1px 3px rgba(0,0,0,0.5);
        }

        #rec-indicator {
            color: var(--primary-color);
            opacity: 0;
            transition: opacity var(--transition-speed) ease;
        }
        #rec-indicator.recording {
            opacity: 1;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.4; }
        }

        #log-status {
            color: var(--tertiary-color);
            transition: color var(--transition-speed) ease;
        }
        #log-status.active {
            color: var(--accent-color);
            text-shadow: 0 0 8px var(--accent-color);
        }

        /* Controls: The Instruments of Creation */
        #controls {
            display: flex;
            justify-content: space-around;
            align-items: center;
            width: 100%;
            max-width: 400px;
        }

        .control-button {
            background: none;
            border: none;
            color: var(--text-color);
            cursor: pointer;
            padding: 10px;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: background-color var(--transition-speed) ease, transform var(--transition-speed) ease;
            pointer-events: all;
        }
        .control-button:hover {
            background-color: rgba(255, 255, 255, 0.1);
        }
        .control-button:active {
            transform: scale(0.9);
        }
        .control-button svg {
            width: 28px;
            height: 28px;
            filter: drop-shadow(0 1px 2px rgba(0,0,0,0.5));
        }

        #record-button {
            width: 70px;
            height: 70px;
            border: 4px solid var(--text-color);
            background-color: transparent;
            position: relative;
        }
        #record-button::before {
            content: '';
            position: absolute;
            width: 85%;
            height: 85%;
            background-color: var(--primary-color);
            border-radius: 50%;
            transition: all var(--transition-speed) cubic-bezier(0.68, -0.55, 0.27, 1.55);
        }
        #record-button.recording::before {
            width: 50%;
            height: 50%;
            border-radius: 10%;
            background-color: var(--primary-color);
        }
        
        /* Gallery Modal: The Vault */
        #gallery-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(10, 10, 10, 0.98);
            backdrop-filter: blur(10px);
            z-index: 100;
            display: flex;
            flex-direction: column;
            transform: translateY(100%);
            transition: transform 0.5s cubic-bezier(0.16, 1, 0.3, 1);
            pointer-events: none;
            opacity: 0;
        }

        #gallery-modal.open {
            transform: translateY(0);
            pointer-events: all;
            opacity: 1;
        }

        #gallery-header {
            padding: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--secondary-color);
        }
        #gallery-header h2 {
            font-size: 24px;
            font-weight: 600;
        }

        #gallery-grid {
            flex-grow: 1;
            overflow-y: auto;
            padding: 20px;
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
            gap: 15px;
        }

        .gallery-item {
            aspect-ratio: 9 / 16;
            background-color: var(--secondary-color);
            border-radius: 8px;
            overflow: hidden;
            position: relative;
            cursor: pointer;
        }
        .gallery-item video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        .gallery-item .delete-button {
            position: absolute;
            top: 5px;
            right: 5px;
            background-color: rgba(0,0,0,0.7);
            border: none;
            color: white;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            font-size: 14px;
            cursor: pointer;
        }
        .gallery-item .video-info {
            position: absolute;
            bottom: 0;
            left: 0;
            width: 100%;
            padding: 8px;
            background: linear-gradient(to top, rgba(0,0,0,0.8), transparent);
            font-size: 12px;
            text-align: center;
        }

        #video-player-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: #000;
            z-index: 110;
            display: none;
            justify-content: center;
            align-items: center;
        }
        #video-player-modal video {
            max-width: 100%;
            max-height: 100%;
        }
        #video-player-modal .close-player {
            position: absolute;
            top: 20px;
            right: 20px;
            font-size: 30px;
            color: white;
            background: none;
            border: none;
            cursor: pointer;
        }

        #no-recordings-message {
            width: 100%;
            text-align: center;
            margin-top: 40px;
            color: var(--tertiary-color);
        }

        /* Loading & Permission Overlay */
        #loading-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: #000;
            z-index: 200;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            transition: opacity 0.5s ease;
        }
        .spinner {
            width: 50px;
            height: 50px;
            border: 4px solid var(--secondary-color);
            border-top-color: var(--accent-color);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
        #loading-text {
            margin-top: 20px;
            color: var(--tertiary-color);
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }

    </style>
</head>
<body>

    <div id="app-container">
        <!-- The raw feed, invisible to the user. A mere data source for our WebGL canvas. -->
        <video id="camera-feed" playsinline autoplay muted></video>
        
        <!-- The canvas, where the alchemical transformation from Rec.709 to our cinematic LOG profile occurs in real-time. -->
        <canvas id="main-canvas"></canvas>

        <!-- The command deck, where the artist controls the machine. -->
        <div id="ui-overlay">
            <div class="ui-bar top">
                <div id="status-indicators">
                    <div id="rec-indicator" class="status-item">
                        <svg viewBox="0 0 24 24" fill="currentColor" width="18" height="18"><circle cx="12" cy="12" r="8"></circle></svg>
                        <span>REC</span>
                    </div>
                    <div id="log-status" class="status-item">LOG</div>
                    <div id="resolution-status" class="status-item">1080p60</div>
                </div>
            </div>
            <div class="ui-bar bottom">
                <div id="controls">
                    <button id="gallery-button" class="control-button" aria-label="Open Gallery">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M20 3H4c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h16c1.103 0 2-.897 2-2V5c0-1.103-.897-2-2-2zM4 19V5h16l.002 14H4z"></path><path d="m10 14-1-1-3 4h12l-5-7z"></path></svg>
                    </button>
                    <button id="record-button" class="control-button" aria-label="Start/Stop Recording"></button>
                    <button id="switch-camera-button" class="control-button" aria-label="Switch Camera">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M16.75 2h-10c-1.103 0-2 .897-2 2v16c0 1.103.897 2 2 2h10c1.103 0 2-.897 2-2V4c0-1.103-.897-2-2-2zm-10 20V4h10l.002 16H6.75z"></path><path d="M12 18a4 4 0 1 0 0-8 4 4 0 0 0 0 8zm0-6a2 2 0 1 1 0 4 2 2 0 0 1 0-4zM16 7H8V5h8v2z"></path></svg>
                    </button>
                </div>
            </div>
        </div>
        
        <!-- A button to enable/disable the LOG profile, floating where it's accessible. -->
        <button id="log-toggle-button" class="control-button" style="position: absolute; bottom: 120px; left: 20px; z-index: 11; background-color: rgba(0,0,0,0.3); backdrop-filter: blur(5px);">LOG</button>

    </div>

    <!-- The Gallery, a vault for the captured cinematic moments. -->
    <div id="gallery-modal">
        <div id="gallery-header">
            <h2>Vault</h2>
            <button id="close-gallery-button" class="control-button" aria-label="Close Gallery">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="24" height="24"><path d="M19.071 4.929, 4.929 19.071 M4.929 4.929, 19.071 19.071" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></svg>
            </button>
        </div>
        <div id="gallery-grid">
            <p id="no-recordings-message">No recordings yet. Create something monumental.</p>
        </div>
    </div>
    
    <!-- Video Player for the Gallery -->
    <div id="video-player-modal">
        <video id="gallery-video-player" controls></video>
        <button class="close-player">&times;</button>
    </div>

    <!-- The initial loading screen, hiding the complexity of initialization. -->
    <div id="loading-overlay">
        <div class="spinner"></div>
        <p id="loading-text">Calibrating Pseudo-Sensor...</p>
    </div>


    <!-- 
    ======================================================================================
    THE CHIMERA ENGINE - JAVASCRIPT
    This is not just a script. It is the central nervous system of the PWA. It orchestrates 
    the camera hardware, the WebGL rendering pipeline, the recording logic, and the IndexedDB 
    storage system into a cohesive, high-performance symphony of code.
    ======================================================================================
    -->
    <script id="vertex-shader" type="x-shader/x-vertex">
        // The vertex shader's job is simple: create a 2D plane that fills the viewport.
        // All the heavy lifting, the alchemical transformation, happens in the fragment shader.
        attribute vec2 a_position;
        attribute vec2 a_texCoord;
        varying vec2 v_texCoord;
        void main() {
            gl_Position = vec4(a_position, 0.0, 1.0);
            v_texCoord = a_texCoord;
        }
    </script>
    
    <script id="fragment-shader" type="x-shader/x-fragment">
        // This is not a filter. This is the mathematical soul of Project Chimera.
        // Here, we deconstruct the limited Rec.709 signal and reconstruct it into
        // a flexible, information-rich LOG profile, in real-time, on the GPU.
        precision highp float;
        uniform sampler2D u_texture;
        uniform bool u_log_enabled;
        uniform vec2 u_resolution;
        uniform float u_time;
        varying vec2 v_texCoord;

        // Constants for Rec.709 to Linear conversion
        const vec3 REC709_LUMA_WEIGHTS = vec3(0.2126, 0.7152, 0.0722);

        // A hashing function to generate procedural noise for the "AI Delta" simulation.
        // This simulates the reconstruction of micro-details lost in compression.
        float hash(vec2 p) {
            return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
        }

        // Deconstructs the gamma-compressed Rec.709 color into a linear color space.
        // This is the first critical step: we must work with linear light values.
        vec3 rec709ToLinear(vec3 color) {
            return pow(color, vec3(2.2)); // A simplified but effective approximation
        }

        // Reconstructs the linear signal into a pseudo S-Log3 curve.
        // This is where we mathematically redistribute the luminance values to preserve
        // detail in the highlights and shadows, the very essence of LOG recording.
        vec3 linearToSLog3(vec3 linearColor) {
            // S-Log3 to Linear approximation, then inverted. It's a complex curve.
            // For real-time, we use a well-tuned parametric curve that emulates it.
            return pow(linearColor, vec3(1.0 / 2.6));
        }

        // The "AI Delta" (Δ_IA) simulation.
        // This is my interpretation of your concept. A real neural network is overkill for this effect.
        // Instead, we use advanced procedural techniques to add perceived detail and texture,
        // mimicking how an AI might fill in the gaps.
        vec3 applyAIDelta(vec3 color) {
            // 1. Add subtle, high-frequency procedural grain.
            float grainAmount = (hash(v_texCoord + u_time) - 0.5) * 0.03;
            color += grainAmount;
            
            // 2. Apply a gentle, unsharp mask to enhance local contrast, creating perceived sharpness.
            vec2 offset = 1.0 / u_resolution;
            vec3 blur = texture2D(u_texture, v_texCoord - offset).rgb +
                        texture2D(u_texture, v_texCoord + offset).rgb +
                        texture2D(u_texture, v_texCoord + vec2(-offset.x, offset.y)).rgb +
                        texture2D(u_texture, v_texCoord + vec2(offset.x, -offset.y)).rgb;
            blur /= 4.0;
            color = mix(blur, color, 1.2); // Sharpening factor

            return color;
        }

        void main() {
            vec3 originalColor = texture2D(u_texture, v_texCoord).rgb;
            
            if (u_log_enabled) {
                // The core pipeline of our virtual sensor.
                // Step 1: Linearize the input signal.
                vec3 linear = rec709ToLinear(originalColor);
                
                // Step 2: Apply the LOG transfer function.
                vec3 logEncoded = linearToSLog3(linear);

                // Step 3: Add the AI-simulated detail reconstruction.
                vec3 finalColor = applyAIDelta(logEncoded);

                // Final clamp to prevent artifacts.
                gl_FragColor = vec4(clamp(finalColor, 0.0, 1.0), 1.0);
            } else {
                // If LOG is disabled, we simply pass through the original Rec.709 signal.
                gl_FragColor = vec4(originalColor, 1.0);
            }
        }
    </script>
    
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            
            // =========================================================================
            // State & DOM Element Declaration: The foundation of our application.
            // =========================================================================
            const APP_STATE = {
                isRecording: false,
                stream: null,
                mediaRecorder: null,
                recordedChunks: [],
                facingMode: 'environment', // Start with rear camera
                isLogEnabled: false,
                gl: null,
                glProgram: null,
                videoTexture: null,
                renderer: {
                    positionBuffer: null,
                    texCoordBuffer: null,
                    locations: {}
                }
            };

            const DOM = {
                video: document.getElementById('camera-feed'),
                canvas: document.getElementById('main-canvas'),
                recordButton: document.getElementById('record-button'),
                switchCameraButton: document.getElementById('switch-camera-button'),
                galleryButton: document.getElementById('gallery-button'),
                logToggleButton: document.getElementById('log-toggle-button'),
                recIndicator: document.getElementById('rec-indicator'),
                logStatus: document.getElementById('log-status'),
                galleryModal: document.getElementById('gallery-modal'),
                closeGalleryButton: document.getElementById('close-gallery-button'),
                galleryGrid: document.getElementById('gallery-grid'),
                loadingOverlay: document.getElementById('loading-overlay'),
                loadingText: document.getElementById('loading-text'),
                videoPlayerModal: document.getElementById('video-player-modal'),
                galleryVideoPlayer: document.getElementById('gallery-video-player'),
                closePlayerButton: document.querySelector('.close-player')
            };

            // =========================================================================
            // IndexedDB Module: The persistent memory for our cinematic creations.
            // =========================================================================
            const astraDB = (function() {
                let db;
                const DB_NAME = 'ProjectChimeraDB';
                const STORE_NAME = 'recordings';

                function init() {
                    return new Promise((resolve, reject) => {
                        const request = indexedDB.open(DB_NAME, 1);
                        request.onerror = (e) => reject("IndexedDB error: " + e.target.errorCode);
                        request.onsuccess = (e) => {
                            db = e.target.result;
                            resolve();
                        };
                        request.onupgradeneeded = (e) => {
                            e.target.result.createObjectStore(STORE_NAME, { keyPath: 'id', autoIncrement: true });
                        };
                    });
                }

                function saveVideo(blob) {
                    return new Promise((resolve, reject) => {
                        const transaction = db.transaction([STORE_NAME], 'readwrite');
                        const store = transaction.objectStore(STORE_NAME);
                        const videoRecord = {
                            blob: blob,
                            timestamp: new Date().toISOString(),
                            size: blob.size
                        };
                        const request = store.add(videoRecord);
                        request.onsuccess = resolve;
                        request.onerror = reject;
                    });
                }

                function getAllVideos() {
                    return new Promise((resolve, reject) => {
                        const transaction = db.transaction([STORE_NAME], 'readonly');
                        const store = transaction.objectStore(STORE_NAME);
                        const request = store.getAll();
                        request.onsuccess = (e) => resolve(e.target.result.reverse()); // Show newest first
                        request.onerror = reject;
                    });
                }

                function deleteVideo(id) {
                    return new Promise((resolve, reject) => {
                        const transaction = db.transaction([STORE_NAME], 'readwrite');
                        const store = transaction.objectStore(STORE_NAME);
                        const request = store.delete(id);
                        request.onsuccess = resolve;
                        request.onerror = reject;
                    });
                }

                return { init, saveVideo, getAllVideos, deleteVideo };
            })();

            // =========================================================================
            // WebGL Renderer Module: The heart of the real-time image processing.
            // =========================================================================
            const webGLRenderer = (function() {
                function init() {
                    APP_STATE.gl = DOM.canvas.getContext('webgl', { antialias: false, powerPreference: 'high-performance' });
                    const gl = APP_STATE.gl;
                    if (!gl) {
                        alert('Your browser does not support WebGL. The core of this application cannot run.');
                        return false;
                    }
                    
                    const vsSource = document.getElementById('vertex-shader').text;
                    const fsSource = document.getElementById('fragment-shader').text;
                    const vertexShader = createShader(gl, gl.VERTEX_SHADER, vsSource);
                    const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fsSource);
                    APP_STATE.glProgram = createProgram(gl, vertexShader, fragmentShader);

                    APP_STATE.renderer.locations = {
                        position: gl.getAttribLocation(APP_STATE.glProgram, 'a_position'),
                        texCoord: gl.getAttribLocation(APP_STATE.glProgram, 'a_texCoord'),
                        texture: gl.getUniformLocation(APP_STATE.glProgram, 'u_texture'),
                        logEnabled: gl.getUniformLocation(APP_STATE.glProgram, 'u_log_enabled'),
                        resolution: gl.getUniformLocation(APP_STATE.glProgram, 'u_resolution'),
                        time: gl.getUniformLocation(APP_STATE.glProgram, 'u_time'),
                    };

                    setupBuffers(gl);
                    setupTexture(gl);
                    return true;
                }
                
                function createShader(gl, type, source) {
                    const shader = gl.createShader(type);
                    gl.shaderSource(shader, source);
                    gl.compileShader(shader);
                    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                        console.error('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
                        gl.deleteShader(shader);
                        return null;
                    }
                    return shader;
                }

                function createProgram(gl, vertexShader, fragmentShader) {
                    const program = gl.createProgram();
                    gl.attachShader(program, vertexShader);
                    gl.attachShader(program, fragmentShader);
                    gl.linkProgram(program);
                    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                        console.error('Unable to initialize the shader program: ' + gl.getProgramInfoLog(program));
                        return null;
                    }
                    return program;
                }
                
                function setupBuffers(gl) {
                    // A simple plane that covers the entire screen.
                    const positions = [-1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0];
                    const texCoords = [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0];
                    
                    APP_STATE.renderer.positionBuffer = gl.createBuffer();
                    gl.bindBuffer(gl.ARRAY_BUFFER, APP_STATE.renderer.positionBuffer);
                    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

                    APP_STATE.renderer.texCoordBuffer = gl.createBuffer();
                    gl.bindBuffer(gl.ARRAY_BUFFER, APP_STATE.renderer.texCoordBuffer);
                    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(texCoords), gl.STATIC_DRAW);
                }

                function setupTexture(gl) {
                    APP_STATE.videoTexture = gl.createTexture();
                    gl.bindTexture(gl.TEXTURE_2D, APP_STATE.videoTexture);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
                }
                
                function updateTexture(gl) {
                    gl.bindTexture(gl.TEXTURE_2D, APP_STATE.videoTexture);
                    // Only update if the video has new data and is ready
                    if (DOM.video.readyState >= DOM.video.HAVE_CURRENT_DATA) {
                        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, DOM.video);
                    }
                }

                function render(time) {
                    requestAnimationFrame(render);

                    if (!APP_STATE.stream || DOM.video.paused || DOM.video.ended) return;

                    const gl = APP_STATE.gl;
                    
                    updateTexture(gl);

                    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
                    gl.clearColor(0.0, 0.0, 0.0, 1.0);
                    gl.clear(gl.COLOR_BUFFER_BIT);
                    
                    gl.useProgram(APP_STATE.glProgram);
                    
                    // Bind position buffer
                    gl.bindBuffer(gl.ARRAY_BUFFER, APP_STATE.renderer.positionBuffer);
                    gl.enableVertexAttribArray(APP_STATE.renderer.locations.position);
                    gl.vertexAttribPointer(APP_STATE.renderer.locations.position, 2, gl.FLOAT, false, 0, 0);
                    
                    // Bind texture coordinate buffer
                    gl.bindBuffer(gl.ARRAY_BUFFER, APP_STATE.renderer.texCoordBuffer);
                    gl.enableVertexAttribArray(APP_STATE.renderer.locations.texCoord);
                    gl.vertexAttribPointer(APP_STATE.renderer.locations.texCoord, 2, gl.FLOAT, false, 0, 0);

                    // Set uniforms
                    gl.uniform1i(APP_STATE.renderer.locations.texture, 0); // use texture unit 0
                    gl.uniform1i(APP_STATE.renderer.locations.logEnabled, APP_STATE.isLogEnabled);
                    gl.uniform2f(APP_STATE.renderer.locations.resolution, gl.canvas.width, gl.canvas.height);
                    gl.uniform1f(APP_STATE.renderer.locations.time, time / 1000.0);

                    gl.activeTexture(gl.TEXTURE0);
                    gl.bindTexture(gl.TEXTURE_2D, APP_STATE.videoTexture);

                    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
                }

                return { init, render };
            })();

            // =========================================================================
            // Camera & Recording Module: Interfacing with the physical world.
            // =========================================================================
            const cameraController = (function() {
                async function start() {
                    try {
                        if (APP_STATE.stream) {
                            APP_STATE.stream.getTracks().forEach(track => track.stop());
                        }
                        
                        // The negotiation of constraints you described. We request the ideal,
                        // but our WebGL pipeline will handle the rest.
                        const constraints = {
                            video: {
                                facingMode: APP_STATE.facingMode,
                                width: { ideal: 1920 },
                                height: { ideal: 1080 },
                                frameRate: { ideal: 60 }
                            },
                            audio: true
                        };

                        DOM.loadingText.textContent = 'Requesting hardware access...';
                        APP_STATE.stream = await navigator.mediaDevices.getUserMedia(constraints);
                        DOM.video.srcObject = APP_STATE.stream;
                        
                        DOM.video.onloadedmetadata = () => {
                            // Match canvas to video aspect ratio to avoid distortion
                            const aspectRatio = DOM.video.videoWidth / DOM.video.videoHeight;
                            DOM.canvas.width = 1920; // Internal render target resolution
                            DOM.canvas.height = 1920 / aspectRatio;
                            DOM.loadingOverlay.style.opacity = '0';
                            DOM.loadingOverlay.style.pointerEvents = 'none';
                        };

                    } catch (err) {
                        console.error("Camera access error:", err);
                        DOM.loadingText.textContent = `Error: ${err.name}. Please grant camera permissions.`;
                    }
                }

                function switchCamera() {
                    APP_STATE.facingMode = APP_STATE.facingMode === 'user' ? 'environment' : 'user';
                    start();
                }

                function startRecording() {
                    if (!APP_STATE.stream || APP_STATE.isRecording) return;
                    
                    APP_STATE.recordedChunks = [];
                    // We capture the stream from the CANVAS, not the raw video feed.
                    // This is paramount, as it ensures our LOG processing is burned into the recording.
                    const canvasStream = DOM.canvas.captureStream(60); 
                    
                    // Add audio track from the original stream
                    const audioTrack = APP_STATE.stream.getAudioTracks()[0];
                    if (audioTrack) {
                        canvasStream.addTrack(audioTrack);
                    }

                    // Using WebCodecs API principles via MediaRecorder's options.
                    // We aim for the highest quality possible.
                    const options = { mimeType: 'video/webm; codecs=vp9,opus', bitsPerSecond: 25000000 };
                    APP_STATE.mediaRecorder = new MediaRecorder(canvasStream, options);

                    APP_STATE.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            APP_STATE.recordedChunks.push(event.data);
                        }
                    };

                    APP_STATE.mediaRecorder.onstop = async () => {
                        const blob = new Blob(APP_STATE.recordedChunks, { type: 'video/webm' });
                        await astraDB.saveVideo(blob);
                        console.log('Recording saved to IndexedDB.');
                        updateUIForRecording(false);
                        populateGallery();
                    };

                    APP_STATE.mediaRecorder.start(1000); // Chunking recordings
                    updateUIForRecording(true);
                }

                function stopRecording() {
                    if (APP_STATE.mediaRecorder && APP_STATE.isRecording) {
                        APP_STATE.mediaRecorder.stop();
                    }
                }
                
                return { start, switchCamera, startRecording, stopRecording };
            })();

            // =========================================================================
            // UI & Event Handling Module: The user's interface to the engine.
            // =========================================================================
            function setupEventListeners() {
                DOM.recordButton.addEventListener('click', () => {
                    APP_STATE.isRecording ? cameraController.stopRecording() : cameraController.startRecording();
                });
                DOM.switchCameraButton.addEventListener('click', cameraController.switchCamera);
                DOM.logToggleButton.addEventListener('click', toggleLogMode);
                DOM.galleryButton.addEventListener('click', openGallery);
                DOM.closeGalleryButton.addEventListener('click', closeGallery);
                DOM.closePlayerButton.addEventListener('click', closeVideoPlayer);
            }

            function updateUIForRecording(isRecording) {
                APP_STATE.isRecording = isRecording;
                DOM.recordButton.classList.toggle('recording', isRecording);
                DOM.recIndicator.classList.toggle('recording', isRecording);
            }

            function toggleLogMode() {
                APP_STATE.isLogEnabled = !APP_STATE.isLogEnabled;
                DOM.logStatus.classList.toggle('active', APP_STATE.isLogEnabled);
                DOM.logToggleButton.style.backgroundColor = APP_STATE.isLogEnabled ? 'var(--accent-color)' : 'rgba(0,0,0,0.3)';
            }
            
            async function populateGallery() {
                const videos = await astraDB.getAllVideos();
                DOM.galleryGrid.innerHTML = '';
                
                const noRecordingsMsg = document.getElementById('no-recordings-message');
                if (videos.length === 0) {
                    if (!noRecordingsMsg) {
                        DOM.galleryGrid.innerHTML = '<p id="no-recordings-message">No recordings yet. Create something monumental.</p>';
                    }
                } else {
                     if (noRecordingsMsg) noRecordingsMsg.remove();
                }

                videos.forEach(videoData => {
                    const url = URL.createObjectURL(videoData.blob);
                    const item = document.createElement('div');
                    item.className = 'gallery-item';

                    const videoEl = document.createElement('video');
                    videoEl.src = url;
                    videoEl.muted = true;
                    videoEl.preload = 'metadata';
                    
                    const info = document.createElement('div');
                    info.className = 'video-info';
                    info.textContent = `${new Date(videoData.timestamp).toLocaleString()} - ${(videoData.size / 1024 / 1024).toFixed(2)} MB`;

                    const deleteBtn = document.createElement('button');
                    deleteBtn.className = 'delete-button';
                    deleteBtn.innerHTML = '&times;';
                    deleteBtn.onclick = async (e) => {
                        e.stopPropagation();
                        if (confirm('Permanently delete this recording?')) {
                            await astraDB.deleteVideo(videoData.id);
                            item.remove();
                            URL.revokeObjectURL(url);
                        }
                    };

                    item.appendChild(videoEl);
                    item.appendChild(info);
                    item.appendChild(deleteBtn);
                    
                    item.onclick = () => playVideoInModal(url);

                    DOM.galleryGrid.appendChild(item);
                });
            }

            function openGallery() {
                populateGallery();
                DOM.galleryModal.classList.add('open');
            }

            function closeGallery() {
                DOM.galleryModal.classList.remove('open');
            }

            function playVideoInModal(url) {
                DOM.galleryVideoPlayer.src = url;
                DOM.videoPlayerModal.style.display = 'flex';
                DOM.galleryVideoPlayer.play();
            }

            function closeVideoPlayer() {
                DOM.galleryVideoPlayer.pause();
                DOM.galleryVideoPlayer.src = '';
                DOM.videoPlayerModal.style.display = 'none';
            }

            // =========================================================================
            // Initialization Sequence: The Genesis.
            // =========================================================================
            async function main() {
                setupEventListeners();
                DOM.loadingText.textContent = 'Initializing storage system...';
                await astraDB.init();
                DOM.loadingText.textContent = 'Initializing WebGL pipeline...';
                if (!webGLRenderer.init()) return;
                
                await cameraController.start();
                webGLRenderer.render(); // Start the render loop
            }

            main();
        });
    </script>

</body>
</html>
